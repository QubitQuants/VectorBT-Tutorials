{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import vectorbtpro as vbt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiting Forex Data from Dukascopy\n",
    "For acquiring historical market data from Dukascopy, I used this nodejs package called [`dukascopy-node`](https://github.com/Leo4815162342/dukascopy-node).\n",
    "<br>The following are the commands I used to download `M1` (1 minute ) data for the following symbols:<br>\n",
    "```javascript\n",
    "npx dukascopy-node -i audnzd -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "npx dukascopy-node -i audnzd -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "\n",
    "npx dukascopy-node -i eurgbp -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "npx dukascopy-node -i eurgbp -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "\n",
    "npx dukascopy-node -i gbpjpy -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "npx dukascopy-node -i gbpjpy -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "\n",
    "npx dukascopy-node -i usdjpy -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "npx dukascopy-node -i usdjpy -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "\n",
    "npx dukascopy-node -i usdcad -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "npx dukascopy-node -i usdcad -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "\n",
    "npx dukascopy-node -i eurusd -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "npx dukascopy-node -i eurusd -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "\n",
    "npx dukascopy-node -i audusd -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "npx dukascopy-node -i audusd -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "\n",
    "npx dukascopy-node -i gbpusd -p ask -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "npx dukascopy-node -i gbpusd -p bid -from 2019-01-01 to 2022-12-31 -t m1 -v true -f csv\n",
    "```\n",
    "The free data `1m` provided by Dukascopy has some missing data and one needs to validate it for data quality auditing with\n",
    "other preferable paid data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bid_ask_data(ask_file : str, bid_file : str, lowercase_columns = False, set_time_index = False) -> pd.DataFrame:\n",
    "    \"\"\"Reads and combines the bid and ask csv files of duksascopy historical market data, into a single OHLCV dataframe.\"\"\"\n",
    "    df_ask = pd.read_csv(ask_file, infer_datetime_format = True)\n",
    "    df_bid = pd.read_csv(bid_file, infer_datetime_format = True)\n",
    "    df_ask_columns = list(df_ask.columns)\n",
    "    df_bid_columns = list(df_bid.columns)    \n",
    "    cols_avg = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]     \n",
    "    cols_avg = cols_avg + ['Timestamp'] if 'timestamp' in df_ask_columns else cols_avg     \n",
    "    df_ask.columns = df_ask.columns.str.title()\n",
    "    df_bid.columns = df_bid.columns.str.title()   \n",
    "\n",
    "    ## Average OHLCV columns for bid and ask data\n",
    "    df_avg = (df_bid[cols_avg] + df_ask[cols_avg]) / 2.0\n",
    "    df_avg = df_avg[df_avg[\"Volume\"] > 0.0].reset_index()\n",
    "\n",
    "    ## Case when we downloaded Dukascopy historical market data from node package: dukascopy-node\n",
    "    if ('timestamp' in df_ask_columns) or ('timestamp' in df_bid_columns):       \n",
    "        df_avg['time'] = pd.to_datetime(df_avg['Timestamp'], unit = 'ms')\n",
    "        df_avg.drop(columns = [\"Timestamp\"],inplace = True)\n",
    "\n",
    "    ## Case when we downloaded Dukascopy historical market data from website\n",
    "    if (\"Local time\" in df_ask_columns) or (\"Local time\" in df_bid_columns):\n",
    "        print(f\"Columns in df_avg:{df_avg.columns}\")\n",
    "        df_avg[\"time\"] = df_ask[\"Local Time\"]\n",
    "        ## Strip ms and GMT TZ in time column\n",
    "        df_avg[\"time\"] = df_avg[\"time\"].str.replace(r\".\\d{3} GMT[+-]\\d\\d\\d\\d\", '', regex = True) \n",
    "\n",
    "    if \"index\" in list(df_avg.columns):\n",
    "        # print(\"index column found in dataframe, so dropping them\")\n",
    "        df_avg.drop(labels = \"index\", axis = 1, inplace = True)\n",
    "\n",
    "    if lowercase_columns:\n",
    "        df_avg.columns= df_avg.columns.str.lower()\n",
    "        \n",
    "    if set_time_index:\n",
    "        df_avg[\"time\"] = pd.to_datetime(df_avg[\"time\"],format='%d.%m.%Y %H:%M:%S')\n",
    "        df_avg = df_avg.set_index(\"time\")      \n",
    "    return df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DataFrame Slicing based on nr. of rows on 1m dataframe\n",
    "def slice_df_by_1m_rows(df : pd.DataFrame, nr_days_to_slice : int):\n",
    "    \"\"\"Slice the historical dataframe from most recent to the nr. of days specified\"\"\"\n",
    "    mins_per_day = 24 * 60\n",
    "    nr_days_to_slice = 365 * mins_per_day\n",
    "    df = df.iloc[-nr_days_to_slice:].reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify FileNames of Bid / Ask data downloaded from DukaScopy\n",
    "bid_ask_files = {\n",
    "    \"GBPUSD\" : {\"Bid\": \"gbpusd-m1-bid-2019-01-01-2023-01-13.csv\",\n",
    "                \"Ask\": \"gbpusd-m1-ask-2019-01-01-2023-01-13.csv\"},\n",
    "    \"EURUSD\" : {\"Bid\": \"eurusd-m1-bid-2019-01-01-2023-01-13.csv\",\n",
    "                \"Ask\": \"eurusd-m1-ask-2019-01-01-2023-01-13.csv\"},\n",
    "    \"AUDUSD\" : {\"Bid\": \"audusd-m1-bid-2019-01-01-2023-01-13.csv\",\n",
    "                \"Ask\": \"audusd-m1-ask-2019-01-01-2023-01-13.csv\"},\n",
    "    \"USDCAD\" : {\"Bid\": \"usdcad-m1-bid-2019-01-01-2023-01-13.csv\",\n",
    "                \"Ask\": \"usdcad-m1-ask-2019-01-01-2023-01-13.csv\"},\n",
    "    \"USDJPY\" : {\"Bid\": \"usdjpy-m1-bid-2019-01-01-2023-01-13.csv\",\n",
    "                \"Ask\": \"usdjpy-m1-ask-2019-01-01-2023-01-13.csv\"},\n",
    "    \"GBPJPY\" : {\"Bid\": \"gbpjpy-m1-bid-2019-01-01-2023-01-13.csv\",\n",
    "                \"Ask\": \"gbpjpy-m1-ask-2019-01-01-2023-01-13.csv\"},\n",
    "    \"EURGBP\" : {\"Bid\": \"eurgbp-m1-bid-2019-01-01-2023-01-16.csv\",\n",
    "                \"Ask\": \"eurgbp-m1-ask-2019-01-01-2023-01-16.csv\"},\n",
    "    \"GBPAUD\" : {\"Bid\": \"gbpaud-m1-bid-2019-01-01-2023-01-16.csv\",\n",
    "                \"Ask\": \"gbpaud-m1-ask-2019-01-01-2023-01-16.csv\"}                                                                           \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GBPUSD\n",
      "ASK File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/gbpusd-m1-ask-2019-01-01-2023-01-13.csv \n",
      "BID File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/gbpusd-m1-bid-2019-01-01-2023-01-13.csv\n",
      "\n",
      "EURUSD\n",
      "ASK File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/eurusd-m1-ask-2019-01-01-2023-01-13.csv \n",
      "BID File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/eurusd-m1-bid-2019-01-01-2023-01-13.csv\n",
      "\n",
      "AUDUSD\n",
      "ASK File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/audusd-m1-ask-2019-01-01-2023-01-13.csv \n",
      "BID File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/audusd-m1-bid-2019-01-01-2023-01-13.csv\n",
      "\n",
      "USDCAD\n",
      "ASK File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/usdcad-m1-ask-2019-01-01-2023-01-13.csv \n",
      "BID File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/usdcad-m1-bid-2019-01-01-2023-01-13.csv\n",
      "\n",
      "USDJPY\n",
      "ASK File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/usdjpy-m1-ask-2019-01-01-2023-01-13.csv \n",
      "BID File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/usdjpy-m1-bid-2019-01-01-2023-01-13.csv\n",
      "\n",
      "GBPJPY\n",
      "ASK File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/gbpjpy-m1-ask-2019-01-01-2023-01-13.csv \n",
      "BID File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/gbpjpy-m1-bid-2019-01-01-2023-01-13.csv\n",
      "\n",
      "EURGBP\n",
      "ASK File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/eurgbp-m1-ask-2019-01-01-2023-01-16.csv \n",
      "BID File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/eurgbp-m1-bid-2019-01-01-2023-01-16.csv\n",
      "\n",
      "GBPAUD\n",
      "ASK File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/gbpaud-m1-ask-2019-01-01-2023-01-16.csv \n",
      "BID File PATH: /Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/gbpaud-m1-bid-2019-01-01-2023-01-16.csv\n",
      "CPU times: user 2.86 s, sys: 721 ms, total: 3.58 s\n",
      "Wall time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "## Write everything into one single HDF5 file indexed by keys for the various symbols\n",
    "folder_path = \"/Users/dilip.rajkumar/Documents/Dukascopy_Historical_Data/\"\n",
    "output_file_path = \"/Users/dilip.rajkumar/Documents/vbtpro_tuts_private/data/MultiAsset_OHLCV_3Y_m1.h5\"\n",
    "for symbol in bid_ask_files.keys():\n",
    "    print(f'\\n{symbol}')\n",
    "    ask_csv_file = folder_path + bid_ask_files[symbol][\"Ask\"]\n",
    "    bid_csv_file = folder_path + bid_ask_files[symbol][\"Bid\"]\n",
    "    print(\"ASK File PATH:\",ask_csv_file,'\\nBID File PATH:',bid_csv_file)\n",
    "    df = read_bid_ask_data(ask_csv_file, bid_csv_file, set_time_index = True)\n",
    "    df.to_hdf(output_file_path, key=symbol)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring Crypto Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acquire multi-asset 1m crypto data from Binance using vbt Wrapper\n",
    "\n",
    "data = vbt.BinanceData.fetch(\n",
    "    [\"BTCUSDT\", \"ETHUSDT\", \"BNBUSDT\", \"XRPUSDT\", \"ADAUSDT\"], \n",
    "    start=\"2019-01-01 UTC\", \n",
    "    end=\"2022-12-01 UTC\",\n",
    "    timeframe=\"1m\"\n",
    "    )\n",
    "\n",
    "## Save acquired data locally for persistance\n",
    "data.to_hdf(\"/Users/dilip.rajkumar/Documents/vbtpro_tuts_private/data/Binance_MultiAsset_OHLCV_3Y_m1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vbt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct 24 2022, 11:04:07) [Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "553d3b352623cb609a2efe4df91242fdc89d5ebcee56d9279e2aa2c11b529c13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
